{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41578cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trendingAllTime = pd.DataFrame( columns=['Title', 'Author', 'Year Published', 'Number of Logs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca9ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomic Habits\n",
      "It Ends With Us\n",
      "The 48 Laws of Power\n",
      "The Subtle Art of Not Giving a F*ck\n",
      "Um casamento arranjado\n",
      "Rich Dad, Poor Dad\n",
      "Harry Potter and the Philosopher's Stone\n",
      "It Starts with Us\n",
      "Control Your Mind and Master Your Feelings\n",
      "Think and Grow Rich\n",
      "Latidos Que No Dije\n",
      "How to Win Friends and Influence People\n",
      "Twisted Love\n",
      "A Game of Thrones\n",
      "It\n",
      "A Court of Mist and Fury\n",
      "The Psychology of Money\n",
      "The Love Hypothesis\n",
      "Shatter Me\n",
      "Haunting Adeline\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a request to the website and get the HTML content\n",
    "url = 'https://openlibrary.org/trending/forever'  # Replace with the URL of the website you're scraping\n",
    "\n",
    "# Make a request to the website and check the status code\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all the h2 elements with the specific class\n",
    "    mydivs = soup.find_all(\"a\", class_=\"results\")\n",
    "\n",
    "    # Loop through each element and print the text\n",
    "    for blueText in mydivs:\n",
    "        print(blueText.get_text(strip=True)) # get_text() extracts the inner text, and strip() removes any extra whitespace\n",
    "\n",
    "        new_row = {'Title': blueText.get_text(strip=True)}\n",
    "        trendingAllTime = trendingAllTime._append(new_row, ignore_index=True)\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve the page, status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61923eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Title Author Year Published  \\\n",
      "0                                Atomic Habits    NaN            NaN   \n",
      "1                              It Ends With Us    NaN            NaN   \n",
      "2                         The 48 Laws of Power    NaN            NaN   \n",
      "3          The Subtle Art of Not Giving a F*ck    NaN            NaN   \n",
      "4                       Um casamento arranjado    NaN            NaN   \n",
      "5                           Rich Dad, Poor Dad    NaN            NaN   \n",
      "6     Harry Potter and the Philosopher's Stone    NaN            NaN   \n",
      "7                            It Starts with Us    NaN            NaN   \n",
      "8   Control Your Mind and Master Your Feelings    NaN            NaN   \n",
      "9                          Think and Grow Rich    NaN            NaN   \n",
      "10                         Latidos Que No Dije    NaN            NaN   \n",
      "11     How to Win Friends and Influence People    NaN            NaN   \n",
      "12                                Twisted Love    NaN            NaN   \n",
      "13                           A Game of Thrones    NaN            NaN   \n",
      "14                                          It    NaN            NaN   \n",
      "15                    A Court of Mist and Fury    NaN            NaN   \n",
      "16                     The Psychology of Money    NaN            NaN   \n",
      "17                         The Love Hypothesis    NaN            NaN   \n",
      "18                                  Shatter Me    NaN            NaN   \n",
      "19                            Haunting Adeline    NaN            NaN   \n",
      "\n",
      "   Number of Logs  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "5             NaN  \n",
      "6             NaN  \n",
      "7             NaN  \n",
      "8             NaN  \n",
      "9             NaN  \n",
      "10            NaN  \n",
      "11            NaN  \n",
      "12            NaN  \n",
      "13            NaN  \n",
      "14            NaN  \n",
      "15            NaN  \n",
      "16            NaN  \n",
      "17            NaN  \n",
      "18            NaN  \n",
      "19            NaN  \n"
     ]
    }
   ],
   "source": [
    "print(trendingAllTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e634d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "41\n",
      "2016—41 editions\n",
      "2012\n",
      "34\n",
      "2012—34 editions\n",
      "1998\n",
      "52\n",
      "1998—52 editions\n",
      "2016\n",
      "41\n",
      "2016—41 editions\n",
      "2019\n",
      "15\n",
      "2019—15 editions\n",
      "1990\n",
      "78\n",
      "1990—78 editions\n",
      "1997\n",
      "33\n",
      "1997—337 editions\n",
      "2022\n",
      "16\n",
      "2022—16 editions\n",
      "2019\n",
      "3 \n",
      "2019—3 editions\n",
      "1937\n",
      "27\n",
      "1937—279 editions\n",
      "2022\n",
      "2 \n",
      "2022—2 editions\n",
      "1913\n",
      "15\n",
      "1913—151 editions\n",
      "2021\n",
      "13\n",
      "2021—13 editions\n",
      "1996\n",
      "86\n",
      "1996—86 editions\n",
      "1925\n",
      "95\n",
      "1925—95 editions\n",
      "2014\n",
      "25\n",
      "2014—25 editions\n",
      "2020\n",
      "9 \n",
      "2020—9 editions\n",
      "2021\n",
      "7 \n",
      "2021—7 editions\n",
      "2011\n",
      "13\n",
      "2011—13 editions\n",
      "2021\n",
      "9 \n",
      "2021—9 editions\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a request to the website and get the HTML content\n",
    "url = 'https://openlibrary.org/trending/forever'  # Replace with the URL of the website you're scraping\n",
    "\n",
    "# Make a request to the website and check the status code\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all the h2 elements with the specific class\n",
    "    mydivs = soup.find_all(\"span\", class_=\"resultDetails\")\n",
    "\n",
    "    # Loop through each element and print the text\n",
    "    for blueText in mydivs:\n",
    "        step1 = blueText.get_text(strip=True).replace('First published in ', '', 1)\n",
    "        year = step1[0:4]\n",
    "        print(year)\n",
    "        editions = step1[5: 7]\n",
    "        print(editions)\n",
    "\n",
    "        print(blueText.get_text(strip=True).replace('First published in ', '', 1)) # get_text() extracts the inner text, and strip() removes any extra whitespace\n",
    "\n",
    "        new_row = {'Year Published': year}\n",
    "        trendingAllTime = trendingAllTime._append(new_row, ignore_index=True)\n",
    "        new_row = {'Year Published': year}\n",
    "        trendingAllTime = trendingAllTime._append(new_row, ignore_index=True)\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve the page, status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec46068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Clear\n",
      "Colleen Hoover\n",
      "Robert GreeneandJoost Elffers\n",
      "Mark Manson\n",
      "Zana Kheiron\n",
      "Robert T. KiyosakiandSharon L. Lechter\n",
      "J. K. Rowling\n",
      "Colleen Hoover\n",
      "Eric Robertson - undifferentiated\n",
      "Napoleon Hill\n",
      "Roos\n",
      "Dale Carnegie\n",
      "Ana Huang\n",
      "George R. R. Martin\n",
      "Stephen King\n",
      "Sarah J. Maas\n",
      "Morgan Housel\n",
      "Ali Hazelwood\n",
      "Tahereh Mafi\n",
      "H. D. Carlton\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a request to the website and get the HTML content\n",
    "url = 'https://openlibrary.org/trending/forever'  # Replace with the URL of the website you're scraping\n",
    "\n",
    "# Make a request to the website and check the status code\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all the h2 elements with the specific class\n",
    "    mydivs = soup.find_all(\"span\", class_=\"bookauthor\")\n",
    "\n",
    "    # Loop through each element and print the text\n",
    "    for blueText in mydivs:\n",
    "        print(blueText.get_text(strip=True).replace('by', '', 1)) # get_text() extracts the inner text, and strip() removes any extra whitespace\n",
    "\n",
    "        new_row = {'Author': blueText.get_text(strip=True).replace('by', '', 1)}\n",
    "        trendingAllTime = trendingAllTime._append(new_row, ignore_index=True)\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve the page, status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c479b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomic HabitsbyJames ClearFirst published in 2016—41 editionsLogged 41181 times All Time\n",
      "61\n",
      " 41181 ti\n",
      "It Ends With UsbyColleen HooverFirst published in 2012—34 editionsLogged 40567 times All Time\n",
      "66\n",
      " 40567 ti\n",
      "The 48 Laws of PowerbyRobert GreeneandJoost ElffersFirst published in 1998—52 editionsLogged 34986 times All Time\n",
      "86\n",
      " 34986 ti\n",
      "The Subtle Art of Not Giving a F*ckbyMark MansonFirst published in 2016—41 editionsLogged 30182 times All Time\n",
      "83\n",
      " 30182 ti\n",
      "Um casamento arranjadobyZana KheironFirst published in 2019—15 editionsLogged 23272 times All Time\n",
      "71\n",
      " 23272 ti\n",
      "Rich Dad, Poor DadbyRobert T. KiyosakiandSharon L. LechterFirst published in 1990—78 editionsLogged 23002 times All Time\n",
      "93\n",
      " 23002 ti\n",
      "Harry Potter and the Philosopher's StonebyJ. K. RowlingFirst published in 1997—337 editionsLogged 15987 times All Time\n",
      "91\n",
      " 15987 ti\n",
      "It Starts with UsbyColleen HooverFirst published in 2022—16 editionsLogged 15547 times All Time\n",
      "68\n",
      " 15547 ti\n",
      "Control Your Mind and Master Your FeelingsbyEric Robertson - undifferentiatedFirst published in 2019—3 editionsLogged 15511 times All Time\n",
      "111\n",
      " 15511 ti\n",
      "Think and Grow RichbyNapoleon HillFirst published in 1937—279 editionsLogged 11716 times All Time\n",
      "70\n",
      " 11716 ti\n",
      "Latidos Que No DijebyRoosFirst published in 2022—2 editionsLogged 9778 times All Time\n",
      "59\n",
      " 9778 tim\n",
      "How to Win Friends and Influence PeoplebyDale CarnegieFirst published in 1913—151 editionsLogged 9226 times All Time\n",
      "90\n",
      " 9226 tim\n",
      "Twisted LovebyAna HuangFirst published in 2021—13 editionsLogged 8840 times All Time\n",
      "58\n",
      " 8840 tim\n",
      "A Game of ThronesbyGeorge R. R. MartinFirst published in 1996—86 editionsLogged 8596 times All Time\n",
      "73\n",
      " 8596 tim\n",
      "ItbyStephen KingFirst published in 1925—95 editionsLogged 7917 times All Time\n",
      "51\n",
      " 7917 tim\n",
      "A Court of Mist and FurybySarah J. MaasFirst published in 2014—25 editionsLogged 7827 times All Time\n",
      "74\n",
      " 7827 tim\n",
      "The Psychology of MoneybyMorgan HouselFirst published in 2020—9 editionsLogged 7760 times All Time\n",
      "72\n",
      " 7760 tim\n",
      "The Love HypothesisbyAli HazelwoodFirst published in 2021—7 editionsLogged 7097 times All Time\n",
      "68\n",
      " 7097 tim\n",
      "Shatter MebyTahereh MafiFirst published in 2011—13 editionsLogged 6849 times All Time\n",
      "59\n",
      " 6849 tim\n",
      "Haunting AdelinebyH. D. CarltonFirst published in 2021—9 editionsLogged 6823 times All Time\n",
      "65\n",
      " 6823 tim\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a request to the website and get the HTML content\n",
    "url = 'https://openlibrary.org/trending/forever'  # Replace with the URL of the website you're scraping\n",
    "\n",
    "# Make a request to the website and check the status code\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all the h2 elements with the specific class\n",
    "    mydivs = soup.find_all(\"div\", class_=\"details\")\n",
    "\n",
    "    # Loop through each element and print the text\n",
    "    for blueText in mydivs:\n",
    "        step0 = blueText.get_text(strip=True)\n",
    "        print(blueText.get_text(strip=True)) # get_text() extracts the inner text, and strip() removes any extra whitespace\n",
    "        print(step0.index('Logged'))\n",
    "        print(step0[step0.index('Logged') + 6: step0.index('Logged')+ 15])\n",
    "\n",
    "        \n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve the page, status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d80757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a request to the website and get the HTML content\n",
    "url = 'https://openlibrary.org/trending/forever'  # Replace with the URL of the website you're scraping\n",
    "\n",
    "# Make a request to the website and check the status code\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all the h2 elements with the specific class\n",
    "    mydivs = soup.find_all(\"span\", class_=\"this\")\n",
    "\n",
    "    # Loop through each element and print the text\n",
    "    for blueText in mydivs:\n",
    "        print(blueText.get_text(strip=True)) # get_text() extracts the inner text, and strip() removes any extra whitespace\n",
    "        \n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve the page, status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f385f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `page=2` not found.\n"
     ]
    }
   ],
   "source": [
    "?page=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb9c7b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26932\\894888143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://openlibrary.org/trending/forever?page='\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'page' is not defined"
     ]
    }
   ],
   "source": [
    "while page > 1:\n",
    "    url = 'https://openlibrary.org/trending/forever?page='+ str(page)\n",
    "    page += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa77f72",
   "metadata": {},
   "source": [
    "If I select a random trending book, how many editions is it likely to have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca861b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "12\n",
      "2014—12 editions\n",
      "2020\n",
      "9 \n",
      "2020—9 editions\n",
      "1963\n",
      "11\n",
      "1963—117 editions\n",
      "2020\n",
      "2 \n",
      "2020—2 editions\n",
      "1988\n",
      "13\n",
      "1988—132 editions\n",
      "1949\n",
      "43\n",
      "1949—431 editions\n",
      "2000\n",
      "13\n",
      "2000—138 editions\n",
      "1998\n",
      "27\n",
      "1998—272 editions\n",
      "2008\n",
      "10\n",
      "2008—105 editions\n",
      "2007\n",
      "12\n",
      "2007—121 editions\n",
      "1989\n",
      "74\n",
      "1989—74 editions\n",
      "1813\n",
      "40\n",
      "1813—4035 editions\n",
      "1900\n",
      "93\n",
      "1900—93 editions\n",
      "2005\n",
      "77\n",
      "2005—77 editions\n",
      "2005\n",
      "11\n",
      "2005—116 editions\n",
      "2022\n",
      "8 \n",
      "2022—8 editions\n",
      "1960\n",
      "18\n",
      "1960—187 editions\n",
      "2018\n",
      "16\n",
      "2018—16 editions\n",
      "1999\n",
      "25\n",
      "1999—259 editions\n",
      "2017\n",
      "17\n",
      "2017—17 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2019\n",
      "20\n",
      "2019—20 editions\n",
      "2018\n",
      "16\n",
      "2018—16 editions\n",
      "2011\n",
      "39\n",
      "2011—39 editions\n",
      "2021\n",
      "10\n",
      "2021—10 editions\n",
      "2011\n",
      "33\n",
      "2011—33 editions\n",
      "1937\n",
      "45\n",
      "1937—457 editions\n",
      "2022\n",
      "10\n",
      "2022—10 editions\n",
      "1993\n",
      "22\n",
      "1993—223 editions\n",
      "1901\n",
      "20\n",
      "1901—20 editions\n",
      "2018\n",
      "7 \n",
      "2018—7 editions\n",
      "1952\n",
      "89\n",
      "1952—89 editions\n",
      "2018\n",
      "25\n",
      "2018—25 editions\n",
      "2019\n",
      "22\n",
      "2019—22 editions\n",
      "1952\n",
      "14\n",
      "1952—149 editions\n",
      "1900\n",
      "14\n",
      "1900—1431 editions\n",
      "2020\n",
      "4 \n",
      "2020—4 editions\n",
      "2020\n",
      "3 \n",
      "2020—3 editions\n",
      "2010\n",
      "75\n",
      "2010—75 editions\n",
      "1953\n",
      "24\n",
      "1953—249 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2018\n",
      "4 \n",
      "2018—4 editions\n",
      "1945\n",
      "41\n",
      "1945—412 editions\n",
      "2003\n",
      "19\n",
      "2003—193 editions\n",
      "2022\n",
      "5 \n",
      "2022—5 editions\n",
      "2018\n",
      "9 \n",
      "2018—9 editions\n",
      "1965\n",
      "11\n",
      "1965—116 editions\n",
      "2015\n",
      "8 \n",
      "2015—8 editions\n",
      "2000\n",
      "21\n",
      "2000—21 editions\n",
      "2018\n",
      "15\n",
      "2018—15 editions\n",
      "2001\n",
      "55\n",
      "2001—55 editions\n",
      "2011\n",
      "36\n",
      "2011—36 editions\n",
      "1948\n",
      "16\n",
      "1948—16 editions\n",
      "2015\n",
      "26\n",
      "2015—26 editions\n",
      "2005\n",
      "13\n",
      "2005—136 editions\n",
      "2017\n",
      "10\n",
      "2017—10 editions\n",
      "2013\n",
      "6 \n",
      "2013—6 editions\n",
      "2022\n",
      "5 \n",
      "2022—5 editions\n",
      "2018\n",
      "37\n",
      "2018—37 editions\n",
      "2016\n",
      "10\n",
      "2016—10 editions\n",
      "2017\n",
      "52\n",
      "2017—52 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2015\n",
      "28\n",
      "2015—28 editions\n",
      "2003\n",
      "19\n",
      "2003—195 editions\n",
      "1977\n",
      "94\n",
      "1977—94 editions\n",
      "1892\n",
      "11\n",
      "1892—1131 editions\n",
      "1932\n",
      "50\n",
      "1932—509 editions\n",
      "1988\n",
      "14\n",
      "1988—149 editions\n",
      "1954\n",
      "18\n",
      "1954—186 editions\n",
      "1955\n",
      "13\n",
      "1955—134 editions\n",
      "2022\n",
      "6 \n",
      "2022—6 editions\n",
      "2016\n",
      "4 \n",
      "2016—4 editions\n",
      "1943\n",
      "37\n",
      "1943—371 editions\n",
      "1964\n",
      "21\n",
      "1964—213 editions\n",
      "1999\n",
      "10\n",
      "1999—10 editions\n",
      "2015\n",
      "24\n",
      "2015—24 editions\n",
      "2002\n",
      "82\n",
      "2002—82 editions\n",
      "1985\n",
      "14\n",
      "1985—146 editions\n",
      "1920\n",
      "11\n",
      "1920—1174 editions\n",
      "1997\n",
      "14\n",
      "1997—14 editions\n",
      "2016\n",
      "12\n",
      "2016—12 editions\n",
      "1993\n",
      "10\n",
      "1993—105 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "1993\n",
      "10\n",
      "1993—105 editions\n",
      "2022\n",
      "4 \n",
      "2022—4 editions\n",
      "1925\n",
      "90\n",
      "1925—90 editions\n",
      "1597\n",
      "97\n",
      "1597—972 editions\n",
      "1848\n",
      "18\n",
      "1848—1887 editions\n",
      "1900\n",
      "13\n",
      "1900—130 editions\n",
      "2009\n",
      "8 \n",
      "2009—8 editions\n",
      "1998\n",
      "10\n",
      "1998—107 editions\n",
      "1974\n",
      "11\n",
      "1974—112 editions\n",
      "1847\n",
      "21\n",
      "1847—2129 editions\n",
      "2017\n",
      "15\n",
      "2017—15 editions\n",
      "1988\n",
      "11\n",
      "1988—115 editions\n",
      "1999\n",
      "43\n",
      "1999—43 editions\n",
      "2021\n",
      "6 \n",
      "2021—6 editions\n",
      "2001\n",
      "33\n",
      "2001—33 editions\n",
      "2014\n",
      "12\n",
      "2014—12 editions\n",
      "2016\n",
      "11\n",
      "2016—11 editions\n",
      "2022\n",
      "6 \n",
      "2022—6 editions\n",
      "2004\n",
      "78\n",
      "2004—78 editions\n",
      "1981\n",
      "32\n",
      "1981—32 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2003\n",
      "10\n",
      "2003—108 editions\n",
      "1954\n",
      "25\n",
      "1954—250 editions\n",
      "1986\n",
      "81\n",
      "1986—81 editions\n",
      "2021\n",
      "5 \n",
      "2021—5 editions\n",
      "1952\n",
      "22\n",
      "1952—224 editions\n",
      "2010\n",
      "45\n",
      "2010—45 editions\n",
      "1944\n",
      "26\n",
      "1944—265 editions\n",
      "1988\n",
      "82\n",
      "1988—82 editions\n",
      "1954\n",
      "29\n",
      "1954—296 editions\n",
      "2009\n",
      "20\n",
      "2009—20 editions\n",
      "1979\n",
      "11\n",
      "1979—116 editions\n",
      "1915\n",
      "94\n",
      "1915—948 editions\n",
      "1997\n",
      "11\n",
      "1997—11 editions\n",
      "1937\n",
      "19\n",
      "1937—193 editions\n",
      "1626\n",
      "36\n",
      "1626—365 editions\n",
      "2010\n",
      "45\n",
      "2010—45 editions\n",
      "1946\n",
      "10\n",
      "1946—100 editions\n",
      "1991\n",
      "45\n",
      "1991—45 editions\n",
      "2021\n",
      "8 \n",
      "2021—8 editions\n",
      "2000\n",
      "18\n",
      "2000—18 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2011\n",
      "47\n",
      "2011—47 editions\n",
      "1818\n",
      "21\n",
      "1818—2182 editions\n",
      "1976\n",
      "98\n",
      "1976—98 editions\n",
      "2014\n",
      "22\n",
      "2014—22 editions\n",
      "1999\n",
      "6 \n",
      "1999—6 editions\n",
      "2023\n",
      "8 \n",
      "2023—8 editions\n",
      "1967\n",
      "77\n",
      "1967—77 editions\n",
      "1992\n",
      "49\n",
      "1992—49 editions\n",
      "1897\n",
      "41\n",
      "1897—416 editions\n",
      "2018\n",
      "1 \n",
      "2018—1 edition\n",
      "1942\n",
      "33\n",
      "1942—332 editions\n",
      "2022\n",
      "6 \n",
      "2022—6 editions\n",
      "1865\n",
      "35\n",
      "1865—3546 editions\n",
      "1939\n",
      "18\n",
      "1939—182 editions\n",
      "2005\n",
      "57\n",
      "2005—57 editions\n",
      "2012\n",
      "25\n",
      "2012—25 editions\n",
      "2000\n",
      "20\n",
      "2000—20 editions\n",
      "2011\n",
      "2 \n",
      "2011—2 editions\n",
      "1950\n",
      "15\n",
      "1950—158 editions\n",
      "2013\n",
      "21\n",
      "2013—21 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2013\n",
      "21\n",
      "2013—21 editions\n",
      "1985\n",
      "10\n",
      "1985—103 editions\n",
      "2003\n",
      "1 \n",
      "2003—1 edition\n",
      "2022\n",
      "2 \n",
      "2022—2 editions\n",
      "1994\n",
      "10\n",
      "1994—104 editions\n",
      "2005\n",
      "66\n",
      "2005—66 editions\n",
      "2022\n",
      "2 \n",
      "2022—2 editions\n",
      "1963\n",
      "14\n",
      "1963—149 editions\n",
      "2008\n",
      "39\n",
      "2008—39 editions\n",
      "2022\n",
      "1 \n",
      "2022—1 edition\n",
      "1983\n",
      "26\n",
      "1983—26 editions\n",
      "2018\n",
      "24\n",
      "2018—24 editions\n",
      "2009\n",
      "81\n",
      "2009—81 editions\n",
      "2012\n",
      "19\n",
      "2012—19 editions\n",
      "2020\n",
      "8 \n",
      "2020—8 editions\n",
      "1951\n",
      "97\n",
      "1951—97 editions\n",
      "2019\n",
      "13\n",
      "2019—13 editions\n",
      "2015\n",
      "32\n",
      "2015—32 editions\n",
      "2014\n",
      "11\n",
      "2014—11 editions\n",
      "1897\n",
      "73\n",
      "1897—730 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "1980\n",
      "13\n",
      "1980—136 editions\n",
      "1992\n",
      "78\n",
      "1992—78 editions\n",
      "2001\n",
      "35\n",
      "2001—35 editions\n",
      "2012\n",
      "37\n",
      "2012—37 editions\n",
      "1851\n",
      "11\n",
      "1851—1116 editions\n",
      "1992\n",
      "10\n",
      "1992—10 editions\n",
      "1603\n",
      "13\n",
      "1603—1308 editions\n",
      "2007\n",
      "53\n",
      "2007—53 editions\n",
      "2000\n",
      "16\n",
      "2000—168 editions\n",
      "1950\n",
      "10\n",
      "1950—103 editions\n",
      "1987\n",
      "10\n",
      "1987—104 editions\n",
      "1929\n",
      "17\n",
      "1929—179 editions\n",
      "1883\n",
      "23\n",
      "1883—236 editions\n",
      "1958\n",
      "92\n",
      "1958—92 editions\n",
      "2001\n",
      "10\n",
      "2001—10 editions\n",
      "2007\n",
      "48\n",
      "2007—48 editions\n",
      "1967\n",
      "20\n",
      "1967—203 editions\n",
      "1987\n",
      "48\n",
      "1987—48 editions\n",
      "1962\n",
      "10\n",
      "1962—103 editions\n",
      "1950\n",
      "95\n",
      "1950—95 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2015\n",
      "7 \n",
      "2015—7 editions\n",
      "2018\n",
      "20\n",
      "2018—20 editions\n",
      "2020\n",
      "8 \n",
      "2020—8 editions\n",
      "1933\n",
      "19\n",
      "1933—196 editions\n",
      "1961\n",
      "14\n",
      "1961—149 editions\n",
      "1890\n",
      "22\n",
      "1890—2294 editions\n",
      "2007\n",
      "52\n",
      "2007—52 editions\n",
      "2007\n",
      "57\n",
      "2007—57 editions\n",
      "2014\n",
      "9 \n",
      "2014—9 editions\n",
      "2021\n",
      "3 \n",
      "2021—3 editions\n",
      "1968\n",
      "90\n",
      "1968—90 editions\n",
      "2008\n",
      "37\n",
      "2008—37 editions\n",
      "1800\n",
      "20\n",
      "1800—2059 editions\n",
      "2022\n",
      "4 \n",
      "2022—4 editions\n",
      "2020\n",
      "15\n",
      "2020—15 editions\n",
      "2002\n",
      "19\n",
      "2002—19 editions\n",
      "2020\n",
      "12\n",
      "2020—12 editions\n",
      "2017\n",
      "1 \n",
      "2017—1 edition\n",
      "2015\n",
      "5 \n",
      "2015—5 editions\n",
      "2011\n",
      "29\n",
      "2011—29 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "1973\n",
      "60\n",
      "1973—60 editions\n",
      "1957\n",
      "85\n",
      "1957—85 editions\n",
      "1998\n",
      "35\n",
      "1998—35 editions\n",
      "2013\n",
      "7 \n",
      "2013—7 editions\n",
      "1970\n",
      "14\n",
      "1970—140 editions\n",
      "2020\n",
      "15\n",
      "2020—15 editions\n",
      "1876\n",
      "25\n",
      "1876—2552 editions\n",
      "2018\n",
      "11\n",
      "2018—11 editions\n",
      "2005\n",
      "63\n",
      "2005—63 editions\n",
      "1999\n",
      "35\n",
      "1999—35 editions\n",
      "1997\n",
      "57\n",
      "1997—57 editions\n",
      "2014\n",
      "65\n",
      "2014—65 editions\n",
      "1922\n",
      "11\n",
      "1922—114 editions\n",
      "2007\n",
      "70\n",
      "2007—70 editions\n",
      "1990\n",
      "72\n",
      "1990—72 editions\n",
      "1996\n",
      "91\n",
      "1996—91 editions\n",
      "2006\n",
      "91\n",
      "2006—91 editions\n",
      "1900\n",
      "10\n",
      "1900—1029 editions\n",
      "1961\n",
      "13\n",
      "1961—134 editions\n",
      "2011\n",
      "71\n",
      "2011—71 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2000\n",
      "55\n",
      "2000—55 editions\n",
      "1969\n",
      "75\n",
      "1969—75 editions\n",
      "1875\n",
      "36\n",
      "1875—360 editions\n",
      "1895\n",
      "11\n",
      "1895—1151 editions\n",
      "1709\n",
      "11\n",
      "1709—113 editions\n",
      "1830\n",
      "73\n",
      "1830—731 editions\n",
      "2000\n",
      "59\n",
      "2000—59 editions\n",
      "2001\n",
      "55\n",
      "2001—55 editions\n",
      "2007\n",
      "23\n",
      "2007—23 editions\n",
      "1975\n",
      "6 \n",
      "1975—6 editions\n",
      "2007\n",
      "9 \n",
      "2007—9 editions\n",
      "1990\n",
      "92\n",
      "1990—92 editions\n",
      "2017\n",
      "3 \n",
      "2017—3 editions\n",
      "1998\n",
      "62\n",
      "1998—62 editions\n",
      "1978\n",
      "82\n",
      "1978—82 editions\n",
      "1954\n",
      "27\n",
      "1954—277 editions\n",
      "2022\n",
      "3 \n",
      "2022—3 editions\n",
      "1908\n",
      "12\n",
      "1908—1299 editions\n",
      "1975\n",
      "10\n",
      "1975—104 editions\n",
      "1986\n",
      "31\n",
      "1986—31 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2017\n",
      "5 \n",
      "2017—5 editions\n",
      "2019\n",
      "6 \n",
      "2019—6 editions\n",
      "1847\n",
      "78\n",
      "1847—787 editions\n",
      "2020\n",
      "4 \n",
      "2020—4 editions\n",
      "2018\n",
      "1 \n",
      "2018—1 edition\n",
      "1946\n",
      "18\n",
      "1946—182 editions\n",
      "2010\n",
      "75\n",
      "2010—75 editions\n",
      "2000\n",
      "4 \n",
      "2000—4 editions\n",
      "2011\n",
      "48\n",
      "2011—48 editions\n",
      "2022\n",
      "2 \n",
      "2022—2 editions\n",
      "1936\n",
      "13\n",
      "1936—132 editions\n",
      "1897\n",
      "1 \n",
      "1897—1 edition\n",
      "1792\n",
      "6 \n",
      "1792—6 editions\n",
      "2017\n",
      "9 \n",
      "2017—9 editions\n",
      "1901\n",
      "91\n",
      "1901—91 editions\n",
      "2015\n",
      "12\n",
      "2015—12 editions\n",
      "1990\n",
      "68\n",
      "1990—68 editions\n",
      "1960\n",
      "54\n",
      "1960—54 editions\n",
      "1966\n",
      "78\n",
      "1966—78 editions\n",
      "2012\n",
      "2 \n",
      "2012—2 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "1898\n",
      "42\n",
      "1898—428 editions\n",
      "2000\n",
      "17\n",
      "2000—17 editions\n",
      "2005\n",
      "53\n",
      "2005—53 editions\n",
      "1839\n",
      "12\n",
      "1839—129 editions\n",
      "1515\n",
      "14\n",
      "1515—1405 editions\n",
      "1979\n",
      "73\n",
      "1979—73 editions\n",
      "1508\n",
      "95\n",
      "1508—953 editions\n",
      "2022\n",
      "1 \n",
      "2022—1 edition\n",
      "2014\n",
      "19\n",
      "2014—19 editions\n",
      "1961\n",
      "55\n",
      "1961—55 editions\n",
      "2001\n",
      "33\n",
      "2001—33 editions\n",
      "1946\n",
      "89\n",
      "1946—89 editions\n",
      "2004\n",
      "21\n",
      "2004—21 editions\n",
      "2016\n",
      "3 \n",
      "2016—3 editions\n",
      "2016\n",
      "9 \n",
      "2016—9 editions\n",
      "2016\n",
      "1 \n",
      "2016—1 edition\n",
      "2019\n",
      "7 \n",
      "2019—7 editions\n",
      "1983\n",
      "24\n",
      "1983—24 editions\n",
      "2007\n",
      "47\n",
      "2007—47 editions\n",
      "2016\n",
      "28\n",
      "2016—28 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "2019\n",
      "47\n",
      "2019—47 editions\n",
      "1817\n",
      "87\n",
      "1817—879 editions\n",
      "2011\n",
      "29\n",
      "2011—29 editions\n",
      "2013\n",
      "11\n",
      "2013—11 editions\n",
      "2018\n",
      "2 \n",
      "2018—2 editions\n",
      "1995\n",
      "14\n",
      "1995—142 editions\n",
      "2014\n",
      "14\n",
      "2014—14 editions\n",
      "1600\n",
      "12\n",
      "1600—125 editions\n",
      "1488\n",
      "10\n",
      "1488—1060 editions\n",
      "2023\n",
      "10\n",
      "2023—10 editions\n",
      "2001\n",
      "38\n",
      "2001—38 editions\n",
      "1899\n",
      "45\n",
      "1899—452 editions\n",
      "1939\n",
      "26\n",
      "1939—260 editions\n",
      "2009\n",
      "25\n",
      "2009—25 editions\n",
      "2000\n",
      "25\n",
      "2000—25 editions\n",
      "2012\n",
      "29\n",
      "2012—29 editions\n",
      "1962\n",
      "13\n",
      "1962—132 editions\n",
      "2009\n",
      "44\n",
      "2009—44 editions\n",
      "2012\n",
      "32\n",
      "2012—32 editions\n",
      "2014\n",
      "1 \n",
      "2014—1 edition\n",
      "Error: Unable to retrieve the page, status code 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957\n",
      "9 \n",
      "1957—9 editions\n",
      "1866\n",
      "40\n",
      "1866—405 editions\n",
      "2001\n",
      "17\n",
      "2001—17 editions\n",
      "1880\n",
      "19\n",
      "1880—1984 editions\n",
      "1991\n",
      "19\n",
      "1991—19 editions\n",
      "1985\n",
      "50\n",
      "1985—50 editions\n",
      "1994\n",
      "57\n",
      "1994—57 editions\n",
      "2022\n",
      "5 \n",
      "2022—5 editions\n",
      "1861\n",
      "14\n",
      "1861—1492 editions\n",
      "2010\n",
      "5 \n",
      "2010—5 editions\n",
      "2014\n",
      "3 \n",
      "2014—3 editions\n",
      "2012\n",
      "16\n",
      "2012—16 editions\n",
      "1876\n",
      "89\n",
      "1876—899 editions\n",
      "1983\n",
      "10\n",
      "1983—107 editions\n",
      "1995\n",
      "13\n",
      "1995—13 editions\n",
      "2001\n",
      "76\n",
      "2001—76 editions\n",
      "2021\n",
      "12\n",
      "2021—12 editions\n",
      "2009\n",
      "38\n",
      "2009—38 editions\n",
      "2001\n",
      "22\n",
      "2001—22 editions\n",
      "Error: Unable to retrieve the page, status code 200\n",
      "1991\n",
      "56\n",
      "1991—56 editions\n",
      "2003\n",
      "55\n",
      "2003—55 editions\n",
      "2006\n",
      "65\n",
      "2006—65 editions\n",
      "2019\n",
      "1 \n",
      "2019—1 edition\n",
      "1985\n",
      "19\n",
      "1985—19 editions\n",
      "1999\n",
      "99\n",
      "1999—99 editions\n",
      "1900\n",
      "32\n",
      "1900—32 editions\n",
      "1815\n",
      "22\n",
      "1815—2260 editions\n",
      "1911\n",
      "87\n",
      "1911—878 editions\n",
      "1961\n",
      "64\n",
      "1961—64 editions\n",
      "2006\n",
      "88\n",
      "2006—88 editions\n",
      "2007\n",
      "22\n",
      "2007—22 editions\n",
      "1977\n",
      "14\n",
      "1977—147 editions\n",
      "1976\n",
      "94\n",
      "1976—94 editions\n",
      "2017\n",
      "18\n",
      "2017—18 editions\n",
      "1976\n",
      "75\n",
      "1976—75 editions\n",
      "1997\n",
      "54\n",
      "1997—54 editions\n",
      "1984\n",
      "63\n",
      "1984—63 editions\n",
      "2016\n",
      "10\n",
      "2016—10 editions\n",
      "1949\n",
      "12\n",
      "1949—12 editions\n",
      "Error: Unable to retrieve the page, status code 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df = pd.DataFrame(columns=['Editions'])\n",
    "page = 2\n",
    "while page <= 30:\n",
    "    url = 'https://openlibrary.org/trending/forever?page='+ str(page)\n",
    "    \n",
    "    # Make a request to the website and check the status code\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Step 2: Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all the h2 elements with the specific class\n",
    "        mydivs = soup.find_all(\"span\", class_=\"resultDetails\")\n",
    "        \n",
    "        # Loop through each element and print the text\n",
    "        for blueText in mydivs:\n",
    "            step1 = blueText.get_text(strip=True).replace('First published in ', '', 1)\n",
    "            year = step1[0:4]\n",
    "            print(year)\n",
    "            editions = step1[5: 7]\n",
    "            print(editions)\n",
    "\n",
    "            print(blueText.get_text(strip=True).replace('First published in ', '', 1)) # get_text() extracts the inner text, and strip() removes any extra whitespace\n",
    "\n",
    "            new_row = {'Editions': editions}\n",
    "            '''df = df._append(new_row, ignore_index=True)'''\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Error: Unable to retrieve the page, status code {response.status_code}\")\n",
    "    \n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Editions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d177d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
